{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arabic 100k Reviews (Part 2): Classifier\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook is the second part of the Arabic 100k Reviews classification pipeline. Building on the preprocessing work from Part 1, we now focus on building and evaluating a text classification model to predict sentiment (Positive or Negative) from Arabic reviews. This notebook covers vectorization, model training, evaluation, and interpretation of results, demonstrating a complete end-to-end NLP classification pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%pip install farasapy==0.1.1 ir-datasets==0.5.11 ir-measures==0.4.3 joblib==1.5.3 kaggle==1.8.3 matplotlib==3.10.8 nltk==3.9.2 numpy==1.26.4 pandas==2.3.3 pyarabic==0.6.15 pyspellchecker==0.8.4 qalsadi==0.5.1 scikit-learn==1.8.0 seaborn==0.13.2 --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "- Build a text classification model for Arabic sentiment analysis\n",
    "- Apply vectorization techniques (TF-IDF) to convert preprocessed text into numerical features\n",
    "- Train and evaluate a machine learning classifier (Logistic Regression)\n",
    "- Understand model evaluation metrics (accuracy, precision, recall, F1-score, confusion matrix)\n",
    "- Interpret classification results and analyze model performance\n",
    "- Recognize the importance of proper train/test splitting and data preprocessing\n",
    "\n",
    "## Outline\n",
    "\n",
    "1. **Setup and Imports** - Installing dependencies and importing libraries\n",
    "2. **Data Loading** - Loading preprocessed data from Part 1\n",
    "3. **Text Analytics (EDA)** - Analyzing the preprocessed dataset\n",
    "4. **Vectorization** - Converting text to numerical features using TF-IDF\n",
    "5. **Model Training** - Training a Logistic Regression classifier\n",
    "6. **Model Evaluation** - Assessing performance with various metrics\n",
    "7. **Results Interpretation** - Understanding model predictions and errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normal = pd.read_csv('ar_reviews_100k_cleaned.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=45, stop=51, step=1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_ids = df_normal.loc[45:50].index\n",
    "sample_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-8e38e44e-d786-47b1-8dd9-1af166141f5b\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>num_chars</th>\n",
       "      <th>num_words</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>stemmed_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Negative</td>\n",
       "      <td>ضعيف. الانترنت. الفندق</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>ضعيف. الانترنت. الفندق</td>\n",
       "      <td>['ضعف', '.', 'نرن', '.', 'ندق']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Positive</td>\n",
       "      <td>جيد جدا. شكرا لكم.</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>جيد جدا. شكرا لكم.</td>\n",
       "      <td>['جيد', 'جدا', '.', 'شكر', '.']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Positive</td>\n",
       "      <td>رأيي في هذا الكتاب و جزئه الاول ما قاله مصطفي ...</td>\n",
       "      <td>115</td>\n",
       "      <td>23</td>\n",
       "      <td>رأيي في هذا الكتاب و جزئه الاول ما قاله مصطفي ...</td>\n",
       "      <td>['رأي', 'كتب', 'جزئ', 'اول', 'قله', 'صطف', 'حم...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Mixed</td>\n",
       "      <td>حبيت اسلوب الكاتبه كتير وفي جزء كبير روحاني وح...</td>\n",
       "      <td>58</td>\n",
       "      <td>10</td>\n",
       "      <td>حبيت اسلوب الكاتبه كتير وفي جزء كبير روحاني وح...</td>\n",
       "      <td>['حبت', 'سلب', 'كتب', 'كتر', 'وفي', 'جزء', 'كب...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Mixed</td>\n",
       "      <td>جيد . الفدق جيد. الوقع. الاستقبال مركز الخدمة</td>\n",
       "      <td>45</td>\n",
       "      <td>8</td>\n",
       "      <td>جيد . الفدق جيد. الوقع. الاستقبال مركز الخدمة</td>\n",
       "      <td>['جيد', '.', 'فدق', 'جيد', '.', 'وقع', '.', 'ر...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Mixed</td>\n",
       "      <td>تقييمي . . مكتوب من ضمن الخيارات تقديم مشروب م...</td>\n",
       "      <td>102</td>\n",
       "      <td>20</td>\n",
       "      <td>تقييمي . . مكتوب من ضمن الخيارات تقديم مشروب م...</td>\n",
       "      <td>['قيم', '..', 'كتب', 'ضمن', 'خير', 'قدم', 'شرب...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "      \n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8e38e44e-d786-47b1-8dd9-1af166141f5b')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "      \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-8e38e44e-d786-47b1-8dd9-1af166141f5b button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-8e38e44e-d786-47b1-8dd9-1af166141f5b');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "  \n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "       label                                               text  num_chars  \\\n",
       "45  Negative                             ضعيف. الانترنت. الفندق         22   \n",
       "46  Positive                                 جيد جدا. شكرا لكم.         18   \n",
       "47  Positive  رأيي في هذا الكتاب و جزئه الاول ما قاله مصطفي ...        115   \n",
       "48     Mixed  حبيت اسلوب الكاتبه كتير وفي جزء كبير روحاني وح...         58   \n",
       "49     Mixed      جيد . الفدق جيد. الوقع. الاستقبال مركز الخدمة         45   \n",
       "50     Mixed  تقييمي . . مكتوب من ضمن الخيارات تقديم مشروب م...        102   \n",
       "\n",
       "    num_words                                         text_clean  \\\n",
       "45          3                             ضعيف. الانترنت. الفندق   \n",
       "46          4                                 جيد جدا. شكرا لكم.   \n",
       "47         23  رأيي في هذا الكتاب و جزئه الاول ما قاله مصطفي ...   \n",
       "48         10  حبيت اسلوب الكاتبه كتير وفي جزء كبير روحاني وح...   \n",
       "49          8      جيد . الفدق جيد. الوقع. الاستقبال مركز الخدمة   \n",
       "50         20  تقييمي . . مكتوب من ضمن الخيارات تقديم مشروب م...   \n",
       "\n",
       "                                       stemmed_tokens  \n",
       "45                    ['ضعف', '.', 'نرن', '.', 'ندق']  \n",
       "46                    ['جيد', 'جدا', '.', 'شكر', '.']  \n",
       "47  ['رأي', 'كتب', 'جزئ', 'اول', 'قله', 'صطف', 'حم...  \n",
       "48  ['حبت', 'سلب', 'كتب', 'كتر', 'وفي', 'جزء', 'كب...  \n",
       "49  ['جيد', '.', 'فدق', 'جيد', '.', 'وقع', '.', 'ر...  \n",
       "50  ['قيم', '..', 'كتب', 'ضمن', 'خير', 'قدم', 'شرب...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_normal.loc[sample_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Analytics (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After all of this, let's count the number of unique tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"'\", 485844),\n",
       " (',', 233917),\n",
       " (' ', 233917),\n",
       " ('ر', 53539),\n",
       " ('ل', 48464),\n",
       " ('ا', 43229),\n",
       " ('م', 37403),\n",
       " ('ن', 34140),\n",
       " ('د', 33663),\n",
       " ('.', 33605)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "all_tokens = [item for sublist in df_normal['stemmed_tokens'] for item in sublist]\n",
    "token_counter = Counter(all_tokens)\n",
    "token_counter.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many unique words do we have now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique ratio: 0.00%\n"
     ]
    }
   ],
   "source": [
    "unique_ratio = len(token_counter) / len(all_tokens)\n",
    "print(f'Unique ratio: {unique_ratio:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find out which words are associated with positive and negative labels, and which aren't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split counts based on labels\n",
    "counter_positive = Counter([item for sublist in df_normal.loc[df_normal['label'] == 'Positive', 'stemmed_tokens'] for item in sublist])\n",
    "counter_negative = Counter([item for sublist in df_normal.loc[df_normal['label'] == 'Negative', 'stemmed_tokens'] for item in sublist])\n",
    "counter_mixed = Counter([item for sublist in df_normal.loc[df_normal['label'] == 'Mixed', 'stemmed_tokens'] for item in sublist])\n",
    "\n",
    "# Purify each label\n",
    "## Positive\n",
    "pure_positive = counter_positive.copy()\n",
    "pure_positive.subtract(counter_negative)\n",
    "pure_positive.subtract(counter_mixed)\n",
    "\n",
    "## Negative\n",
    "pure_negative = counter_negative.copy()\n",
    "pure_negative.subtract(counter_positive)\n",
    "pure_negative.subtract(counter_mixed)\n",
    "\n",
    "## Neutral\n",
    "pure_mixed = counter_mixed.copy()\n",
    "pure_mixed.subtract(counter_positive)\n",
    "pure_mixed.subtract(counter_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_df1c6_row0_col1 {\n",
       "  background-color: #00441b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_df1c6_row1_col1 {\n",
       "  background-color: #00451c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_df1c6_row2_col1 {\n",
       "  background-color: #00471c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_df1c6_row3_col1 {\n",
       "  background-color: #005020;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_df1c6_row4_col1 {\n",
       "  background-color: #005120;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_df1c6_row5_col1 {\n",
       "  background-color: #005221;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_df1c6_row6_col1 {\n",
       "  background-color: #005e26;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_df1c6_row7_col1 {\n",
       "  background-color: #005f26;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_df1c6_row8_col1 {\n",
       "  background-color: #026f2e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_df1c6_row9_col1 {\n",
       "  background-color: #46ae60;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_df1c6_row10_col1 {\n",
       "  background-color: #4aaf61;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_df1c6_row11_col1 {\n",
       "  background-color: #6ec173;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_df1c6_row12_col1 {\n",
       "  background-color: #70c274;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_df1c6_row13_col1 {\n",
       "  background-color: #7cc87c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_df1c6_row14_col1 {\n",
       "  background-color: #9ed798;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_df1c6_row15_col1 {\n",
       "  background-color: #c6e8bf;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_df1c6_row16_col1, #T_df1c6_row17_col1 {\n",
       "  background-color: #cfecc9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_df1c6_row18_col1, #T_df1c6_row19_col1 {\n",
       "  background-color: #f7fcf5;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_df1c6\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_df1c6_level0_col0\" class=\"col_heading level0 col0\" >token</th>\n",
       "      <th id=\"T_df1c6_level0_col1\" class=\"col_heading level0 col1\" >count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_df1c6_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_df1c6_row0_col0\" class=\"data row0 col0\" >|</td>\n",
       "      <td id=\"T_df1c6_row0_col1\" class=\"data row0 col1\" >-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df1c6_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_df1c6_row1_col0\" class=\"data row1 col0\" >؛</td>\n",
       "      <td id=\"T_df1c6_row1_col1\" class=\"data row1 col1\" >-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df1c6_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_df1c6_row2_col0\" class=\"data row2 col0\" >=</td>\n",
       "      <td id=\"T_df1c6_row2_col1\" class=\"data row2 col1\" >-33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df1c6_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_df1c6_row3_col0\" class=\"data row3 col0\" >إ</td>\n",
       "      <td id=\"T_df1c6_row3_col1\" class=\"data row3 col1\" >-110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df1c6_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_df1c6_row4_col0\" class=\"data row4 col0\" >/</td>\n",
       "      <td id=\"T_df1c6_row4_col1\" class=\"data row4 col1\" >-120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df1c6_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_df1c6_row5_col0\" class=\"data row5 col0\" >آ</td>\n",
       "      <td id=\"T_df1c6_row5_col1\" class=\"data row5 col1\" >-134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df1c6_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_df1c6_row6_col0\" class=\"data row6 col0\" >ؤ</td>\n",
       "      <td id=\"T_df1c6_row6_col1\" class=\"data row6 col1\" >-243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df1c6_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_df1c6_row7_col0\" class=\"data row7 col0\" >؟</td>\n",
       "      <td id=\"T_df1c6_row7_col1\" class=\"data row7 col1\" >-257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df1c6_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_df1c6_row8_col0\" class=\"data row8 col0\" >:</td>\n",
       "      <td id=\"T_df1c6_row8_col1\" class=\"data row8 col1\" >-402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df1c6_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_df1c6_row9_col0\" class=\"data row9 col0\" >ذ</td>\n",
       "      <td id=\"T_df1c6_row9_col1\" class=\"data row9 col1\" >-1165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df1c6_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_df1c6_row10_col0\" class=\"data row10 col0\" >ئ</td>\n",
       "      <td id=\"T_df1c6_row10_col1\" class=\"data row10 col1\" >-1188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df1c6_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_df1c6_row11_col0\" class=\"data row11 col0\" >أ</td>\n",
       "      <td id=\"T_df1c6_row11_col1\" class=\"data row11 col1\" >-1452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df1c6_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_df1c6_row12_col0\" class=\"data row12 col0\" >،</td>\n",
       "      <td id=\"T_df1c6_row12_col1\" class=\"data row12 col1\" >-1469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df1c6_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_df1c6_row13_col0\" class=\"data row13 col0\" >ظ</td>\n",
       "      <td id=\"T_df1c6_row13_col1\" class=\"data row13 col1\" >-1560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df1c6_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_df1c6_row14_col0\" class=\"data row14 col0\" >ء</td>\n",
       "      <td id=\"T_df1c6_row14_col1\" class=\"data row14 col1\" >-1844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df1c6_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_df1c6_row15_col0\" class=\"data row15 col0\" >ز</td>\n",
       "      <td id=\"T_df1c6_row15_col1\" class=\"data row15 col1\" >-2223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df1c6_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_df1c6_row16_col0\" class=\"data row16 col0\" >ة</td>\n",
       "      <td id=\"T_df1c6_row16_col1\" class=\"data row16 col1\" >-2342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df1c6_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_df1c6_row17_col0\" class=\"data row17 col0\" >ث</td>\n",
       "      <td id=\"T_df1c6_row17_col1\" class=\"data row17 col1\" >-2345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df1c6_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_df1c6_row18_col0\" class=\"data row18 col0\" >[</td>\n",
       "      <td id=\"T_df1c6_row18_col1\" class=\"data row18 col1\" >-2987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_df1c6_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_df1c6_row19_col0\" class=\"data row19 col0\" >]</td>\n",
       "      <td id=\"T_df1c6_row19_col1\" class=\"data row19 col1\" >-2987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7cd6fc5a3080>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    pure_positive.most_common(20),\n",
    "    columns=['token', 'count']\n",
    ").style.background_gradient(cmap='Greens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_89cbf_row0_col1 {\n",
       "  background-color: #67000d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_89cbf_row1_col1 {\n",
       "  background-color: #6b010e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_89cbf_row2_col1 {\n",
       "  background-color: #6d010e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_89cbf_row3_col1 {\n",
       "  background-color: #6f020e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_89cbf_row4_col1 {\n",
       "  background-color: #7c0510;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_89cbf_row5_col1 {\n",
       "  background-color: #7e0610;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_89cbf_row6_col1 {\n",
       "  background-color: #900a12;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_89cbf_row7_col1 {\n",
       "  background-color: #9d0d14;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_89cbf_row8_col1 {\n",
       "  background-color: #b11218;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_89cbf_row9_col1 {\n",
       "  background-color: #f96346;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_89cbf_row10_col1 {\n",
       "  background-color: #fb7656;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_89cbf_row11_col1 {\n",
       "  background-color: #fc8161;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_89cbf_row12_col1 {\n",
       "  background-color: #fc8f6f;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_89cbf_row13_col1 {\n",
       "  background-color: #fc9474;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_89cbf_row14_col1 {\n",
       "  background-color: #fcaa8d;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_89cbf_row15_col1 {\n",
       "  background-color: #fcaf93;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_89cbf_row16_col1 {\n",
       "  background-color: #fdc5ae;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_89cbf_row17_col1 {\n",
       "  background-color: #fdc7b2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_89cbf_row18_col1 {\n",
       "  background-color: #fee8de;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_89cbf_row19_col1 {\n",
       "  background-color: #fff5f0;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_89cbf\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_89cbf_level0_col0\" class=\"col_heading level0 col0\" >token</th>\n",
       "      <th id=\"T_89cbf_level0_col1\" class=\"col_heading level0 col1\" >count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_89cbf_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_89cbf_row0_col0\" class=\"data row0 col0\" >|</td>\n",
       "      <td id=\"T_89cbf_row0_col1\" class=\"data row0 col1\" >-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_89cbf_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_89cbf_row1_col0\" class=\"data row1 col0\" >؛</td>\n",
       "      <td id=\"T_89cbf_row1_col1\" class=\"data row1 col1\" >-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_89cbf_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_89cbf_row2_col0\" class=\"data row2 col0\" >=</td>\n",
       "      <td id=\"T_89cbf_row2_col1\" class=\"data row2 col1\" >-33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_89cbf_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_89cbf_row3_col0\" class=\"data row3 col0\" >/</td>\n",
       "      <td id=\"T_89cbf_row3_col1\" class=\"data row3 col1\" >-48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_89cbf_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_89cbf_row4_col0\" class=\"data row4 col0\" >؟</td>\n",
       "      <td id=\"T_89cbf_row4_col1\" class=\"data row4 col1\" >-117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_89cbf_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_89cbf_row5_col0\" class=\"data row5 col0\" >إ</td>\n",
       "      <td id=\"T_89cbf_row5_col1\" class=\"data row5 col1\" >-122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_89cbf_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_89cbf_row6_col0\" class=\"data row6 col0\" >آ</td>\n",
       "      <td id=\"T_89cbf_row6_col1\" class=\"data row6 col1\" >-212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_89cbf_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_89cbf_row7_col0\" class=\"data row7 col0\" >ؤ</td>\n",
       "      <td id=\"T_89cbf_row7_col1\" class=\"data row7 col1\" >-277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_89cbf_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_89cbf_row8_col0\" class=\"data row8 col0\" >:</td>\n",
       "      <td id=\"T_89cbf_row8_col1\" class=\"data row8 col1\" >-414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_89cbf_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_89cbf_row9_col0\" class=\"data row9 col0\" >ذ</td>\n",
       "      <td id=\"T_89cbf_row9_col1\" class=\"data row9 col1\" >-1189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_89cbf_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_89cbf_row10_col0\" class=\"data row10 col0\" >ء</td>\n",
       "      <td id=\"T_89cbf_row10_col1\" class=\"data row10 col1\" >-1324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_89cbf_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_89cbf_row11_col0\" class=\"data row11 col0\" >أ</td>\n",
       "      <td id=\"T_89cbf_row11_col1\" class=\"data row11 col1\" >-1414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_89cbf_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_89cbf_row12_col0\" class=\"data row12 col0\" >ض</td>\n",
       "      <td id=\"T_89cbf_row12_col1\" class=\"data row12 col1\" >-1517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_89cbf_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_89cbf_row13_col0\" class=\"data row13 col0\" >ظ</td>\n",
       "      <td id=\"T_89cbf_row13_col1\" class=\"data row13 col1\" >-1556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_89cbf_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_89cbf_row14_col0\" class=\"data row14 col0\" >ئ</td>\n",
       "      <td id=\"T_89cbf_row14_col1\" class=\"data row14 col1\" >-1720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_89cbf_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_89cbf_row15_col0\" class=\"data row15 col0\" >،</td>\n",
       "      <td id=\"T_89cbf_row15_col1\" class=\"data row15 col1\" >-1757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_89cbf_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_89cbf_row16_col0\" class=\"data row16 col0\" >ة</td>\n",
       "      <td id=\"T_89cbf_row16_col1\" class=\"data row16 col1\" >-1938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_89cbf_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_89cbf_row17_col0\" class=\"data row17 col0\" >غ</td>\n",
       "      <td id=\"T_89cbf_row17_col1\" class=\"data row17 col1\" >-1951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_89cbf_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_89cbf_row18_col0\" class=\"data row18 col0\" >ث</td>\n",
       "      <td id=\"T_89cbf_row18_col1\" class=\"data row18 col1\" >-2277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_89cbf_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_89cbf_row19_col0\" class=\"data row19 col0\" >ى</td>\n",
       "      <td id=\"T_89cbf_row19_col1\" class=\"data row19 col1\" >-2468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7cd72c8babd0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    pure_negative.most_common(20),\n",
    "    columns=['token', 'count']\n",
    ").style.background_gradient(cmap='Reds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_41090_row0_col1 {\n",
       "  background-color: #08306b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_41090_row1_col1 {\n",
       "  background-color: #08316d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_41090_row2_col1 {\n",
       "  background-color: #083674;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_41090_row3_col1 {\n",
       "  background-color: #083776;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_41090_row4_col1 {\n",
       "  background-color: #083d7f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_41090_row5_col1 {\n",
       "  background-color: #084184;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_41090_row6_col1 {\n",
       "  background-color: #08468b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_41090_row7_col1 {\n",
       "  background-color: #084a91;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_41090_row8_col1 {\n",
       "  background-color: #0b559f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_41090_row9_col1 {\n",
       "  background-color: #72b2d8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_41090_row10_col1 {\n",
       "  background-color: #87bddc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_41090_row11_col1 {\n",
       "  background-color: #a1cbe2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_41090_row12_col1 {\n",
       "  background-color: #b0d2e7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_41090_row13_col1 {\n",
       "  background-color: #c7dbef;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_41090_row14_col1 {\n",
       "  background-color: #caddf0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_41090_row15_col1 {\n",
       "  background-color: #cfe1f2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_41090_row16_col1 {\n",
       "  background-color: #e3eef9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_41090_row17_col1 {\n",
       "  background-color: #e7f1fa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_41090_row18_col1 {\n",
       "  background-color: #f3f8fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_41090_row19_col1 {\n",
       "  background-color: #f7fbff;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_41090\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_41090_level0_col0\" class=\"col_heading level0 col0\" >token</th>\n",
       "      <th id=\"T_41090_level0_col1\" class=\"col_heading level0 col1\" >count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_41090_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_41090_row0_col0\" class=\"data row0 col0\" >=</td>\n",
       "      <td id=\"T_41090_row0_col1\" class=\"data row0 col1\" >15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_41090_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_41090_row1_col0\" class=\"data row1 col0\" >|</td>\n",
       "      <td id=\"T_41090_row1_col1\" class=\"data row1 col1\" >2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_41090_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_41090_row2_col0\" class=\"data row2 col0\" >؛</td>\n",
       "      <td id=\"T_41090_row2_col1\" class=\"data row2 col1\" >-41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_41090_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_41090_row3_col0\" class=\"data row3 col0\" >آ</td>\n",
       "      <td id=\"T_41090_row3_col1\" class=\"data row3 col1\" >-52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_41090_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_41090_row4_col0\" class=\"data row4 col0\" >إ</td>\n",
       "      <td id=\"T_41090_row4_col1\" class=\"data row4 col1\" >-98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_41090_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_41090_row5_col0\" class=\"data row5 col0\" >/</td>\n",
       "      <td id=\"T_41090_row5_col1\" class=\"data row5 col1\" >-130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_41090_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_41090_row6_col0\" class=\"data row6 col0\" >؟</td>\n",
       "      <td id=\"T_41090_row6_col1\" class=\"data row6 col1\" >-173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_41090_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_41090_row7_col0\" class=\"data row7 col0\" >ؤ</td>\n",
       "      <td id=\"T_41090_row7_col1\" class=\"data row7 col1\" >-205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_41090_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_41090_row8_col0\" class=\"data row8 col0\" >:</td>\n",
       "      <td id=\"T_41090_row8_col1\" class=\"data row8 col1\" >-304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_41090_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_41090_row9_col0\" class=\"data row9 col0\" >ذ</td>\n",
       "      <td id=\"T_41090_row9_col1\" class=\"data row9 col1\" >-1133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_41090_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_41090_row10_col0\" class=\"data row10 col0\" >،</td>\n",
       "      <td id=\"T_41090_row10_col1\" class=\"data row10 col1\" >-1241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_41090_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_41090_row11_col0\" class=\"data row11 col0\" >ظ</td>\n",
       "      <td id=\"T_41090_row11_col1\" class=\"data row11 col1\" >-1388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_41090_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_41090_row12_col0\" class=\"data row12 col0\" >أ</td>\n",
       "      <td id=\"T_41090_row12_col1\" class=\"data row12 col1\" >-1492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_41090_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_41090_row13_col0\" class=\"data row13 col0\" >ث</td>\n",
       "      <td id=\"T_41090_row13_col1\" class=\"data row13 col1\" >-1655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_41090_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_41090_row14_col0\" class=\"data row14 col0\" >ض</td>\n",
       "      <td id=\"T_41090_row14_col1\" class=\"data row14 col1\" >-1691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_41090_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_41090_row15_col0\" class=\"data row15 col0\" >ء</td>\n",
       "      <td id=\"T_41090_row15_col1\" class=\"data row15 col1\" >-1748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_41090_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_41090_row16_col0\" class=\"data row16 col0\" >غ</td>\n",
       "      <td id=\"T_41090_row16_col1\" class=\"data row16 col1\" >-1981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_41090_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_41090_row17_col0\" class=\"data row17 col0\" >ة</td>\n",
       "      <td id=\"T_41090_row17_col1\" class=\"data row17 col1\" >-2028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_41090_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_41090_row18_col0\" class=\"data row18 col0\" >ى</td>\n",
       "      <td id=\"T_41090_row18_col1\" class=\"data row18 col1\" >-2154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_41090_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_41090_row19_col0\" class=\"data row19 col0\" >ئ</td>\n",
       "      <td id=\"T_41090_row19_col1\" class=\"data row19 col1\" >-2202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7cd6fa927b60>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are the neutral words that are not in the positive or negative\n",
    "pd.DataFrame(\n",
    "    pure_mixed.most_common(20),\n",
    "    columns=['token', 'count']\n",
    ").style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-3737902e-7f5e-4c8c-a6ac-80501ac978b0\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>num_chars</th>\n",
       "      <th>num_words</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>stemmed_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Negative</td>\n",
       "      <td>ضعيف. الانترنت. الفندق</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>ضعيف. الانترنت. الفندق</td>\n",
       "      <td>['ضعف', '.', 'نرن', '.', 'ندق']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Positive</td>\n",
       "      <td>جيد جدا. شكرا لكم.</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>جيد جدا. شكرا لكم.</td>\n",
       "      <td>['جيد', 'جدا', '.', 'شكر', '.']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Positive</td>\n",
       "      <td>رأيي في هذا الكتاب و جزئه الاول ما قاله مصطفي ...</td>\n",
       "      <td>115</td>\n",
       "      <td>23</td>\n",
       "      <td>رأيي في هذا الكتاب و جزئه الاول ما قاله مصطفي ...</td>\n",
       "      <td>['رأي', 'كتب', 'جزئ', 'اول', 'قله', 'صطف', 'حم...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Mixed</td>\n",
       "      <td>حبيت اسلوب الكاتبه كتير وفي جزء كبير روحاني وح...</td>\n",
       "      <td>58</td>\n",
       "      <td>10</td>\n",
       "      <td>حبيت اسلوب الكاتبه كتير وفي جزء كبير روحاني وح...</td>\n",
       "      <td>['حبت', 'سلب', 'كتب', 'كتر', 'وفي', 'جزء', 'كب...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Mixed</td>\n",
       "      <td>جيد . الفدق جيد. الوقع. الاستقبال مركز الخدمة</td>\n",
       "      <td>45</td>\n",
       "      <td>8</td>\n",
       "      <td>جيد . الفدق جيد. الوقع. الاستقبال مركز الخدمة</td>\n",
       "      <td>['جيد', '.', 'فدق', 'جيد', '.', 'وقع', '.', 'ر...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Mixed</td>\n",
       "      <td>تقييمي . . مكتوب من ضمن الخيارات تقديم مشروب م...</td>\n",
       "      <td>102</td>\n",
       "      <td>20</td>\n",
       "      <td>تقييمي . . مكتوب من ضمن الخيارات تقديم مشروب م...</td>\n",
       "      <td>['قيم', '..', 'كتب', 'ضمن', 'خير', 'قدم', 'شرب...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "      \n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3737902e-7f5e-4c8c-a6ac-80501ac978b0')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "      \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-3737902e-7f5e-4c8c-a6ac-80501ac978b0 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-3737902e-7f5e-4c8c-a6ac-80501ac978b0');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "  \n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "       label                                               text  num_chars  \\\n",
       "45  Negative                             ضعيف. الانترنت. الفندق         22   \n",
       "46  Positive                                 جيد جدا. شكرا لكم.         18   \n",
       "47  Positive  رأيي في هذا الكتاب و جزئه الاول ما قاله مصطفي ...        115   \n",
       "48     Mixed  حبيت اسلوب الكاتبه كتير وفي جزء كبير روحاني وح...         58   \n",
       "49     Mixed      جيد . الفدق جيد. الوقع. الاستقبال مركز الخدمة         45   \n",
       "50     Mixed  تقييمي . . مكتوب من ضمن الخيارات تقديم مشروب م...        102   \n",
       "\n",
       "    num_words                                         text_clean  \\\n",
       "45          3                             ضعيف. الانترنت. الفندق   \n",
       "46          4                                 جيد جدا. شكرا لكم.   \n",
       "47         23  رأيي في هذا الكتاب و جزئه الاول ما قاله مصطفي ...   \n",
       "48         10  حبيت اسلوب الكاتبه كتير وفي جزء كبير روحاني وح...   \n",
       "49          8      جيد . الفدق جيد. الوقع. الاستقبال مركز الخدمة   \n",
       "50         20  تقييمي . . مكتوب من ضمن الخيارات تقديم مشروب م...   \n",
       "\n",
       "                                       stemmed_tokens  \n",
       "45                    ['ضعف', '.', 'نرن', '.', 'ندق']  \n",
       "46                    ['جيد', 'جدا', '.', 'شكر', '.']  \n",
       "47  ['رأي', 'كتب', 'جزئ', 'اول', 'قله', 'صطف', 'حم...  \n",
       "48  ['حبت', 'سلب', 'كتب', 'كتر', 'وفي', 'جزء', 'كب...  \n",
       "49  ['جيد', '.', 'فدق', 'جيد', '.', 'وقع', '.', 'ر...  \n",
       "50  ['قيم', '..', 'كتب', 'ضمن', 'خير', 'قدم', 'شرب...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_normal.loc[sample_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to Text Classification\n",
    "\n",
    "Now that we have cleaned and preprocessed our text data, we can build a **text classifier** that predicts the sentiment (Positive, Negative, or Mixed) of Arabic reviews.\n",
    "\n",
    "**What is Text Classification?**\n",
    "\n",
    "Text classification is a supervised machine learning task where we:\n",
    "1. **Extract features** from text (convert text to numbers)\n",
    "2. **Train a model** to learn patterns between features and labels\n",
    "3. **Predict** the class of new, unseen text\n",
    "\n",
    "**Why use word counts?**\n",
    "\n",
    "After cleaning and preprocessing, we have a list of tokens (words) for each review. One simple but effective approach is to:\n",
    "- Count how many times each word appears in each document\n",
    "- Use these counts as features for our classifier\n",
    "- This is called **Bag of Words (BoW)** representation\n",
    "\n",
    "**The Bag of Words Model:**\n",
    "\n",
    "The Bag of Words model represents text as a vector of word counts, ignoring word order and grammar. For example:\n",
    "\n",
    "- Review 1: \"ممتاز رائع\" → `{\"ممتاز\": 1, \"رائع\": 1}`\n",
    "- Review 2: \"ممتاز ممتاز سيء\" → `{\"ممتاز\": 2, \"رائع\": 0, \"سيء\": 1}`\n",
    "\n",
    "This creates a feature matrix where:\n",
    "- Each row = one review\n",
    "- Each column = one unique word in the vocabulary\n",
    "- Each cell = count of that word in that review\n",
    "\n",
    "**Why this works:**\n",
    "\n",
    "From our EDA, we saw that certain words are more associated with positive reviews (e.g., \"ممتاز\", \"رائع\") and others with negative reviews (e.g., \"سيء\", \"ضعيف\"). A classifier can learn these patterns from the word counts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Prepare Text Data for Feature Extraction\n",
    "\n",
    "Our `stemmed_tokens` column contains lists of tokens. To use scikit-learn's `CountVectorizer`, we need to convert these token lists back into text strings (space-separated words).\n",
    "\n",
    "**Why convert back to strings?**\n",
    "\n",
    "- `CountVectorizer` expects text input (strings)\n",
    "- It will handle tokenization internally, but since we've already cleaned and stemmed our text, we want to use our preprocessed tokens\n",
    "- We'll join the tokens with spaces to create clean text strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create Word Count Features\n",
    "\n",
    "We'll use scikit-learn's `CountVectorizer` to convert our processed text into a matrix of word counts.\n",
    "\n",
    "**Key parameters:**\n",
    "- `max_features`: Limit vocabulary size to the most frequent N words (reduces dimensionality)\n",
    "- `min_df`: Ignore words that appear in fewer than N documents (removes rare words)\n",
    "- `max_df`: Ignore words that appear in more than N% of documents (removes common words that appear everywhere)\n",
    "\n",
    "**Why limit features?**\n",
    "- Reduces memory usage\n",
    "- Speeds up training\n",
    "- Can improve generalization by focusing on meaningful words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'text_processed'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'text_processed'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-3975220299.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Transform text to word count matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# This creates a sparse matrix where each row is a review and each column is a word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_normal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text_processed'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_normal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4111\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4112\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4113\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4114\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4115\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3817\u001b[0m             ):\n\u001b[1;32m   3818\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3819\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3820\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3821\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'text_processed'"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create CountVectorizer\n",
    "# We use max_features to limit vocabulary size for efficiency\n",
    "# min_df=2 means words must appear in at least 2 documents\n",
    "vectorizer = CountVectorizer(\n",
    "    max_features=5000,  # Use top 5000 most frequent words\n",
    "    min_df=2,           # Word must appear in at least 2 documents\n",
    "    max_df=0.95         # Ignore words that appear in >95% of documents\n",
    ")\n",
    "\n",
    "# Transform text to word count matrix\n",
    "# This creates a sparse matrix where each row is a review and each column is a word\n",
    "X = vectorizer.fit_transform(df_normal['text_processed'])\n",
    "y = df_normal['label'].values\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Number of reviews: {X.shape[0]}\")\n",
    "print(f\"Number of features (words): {X.shape[1]}\")\n",
    "print(f\"Labels: {np.unique(y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Understanding the Feature Matrix:**\n",
    "\n",
    "The `X` matrix is sparse (mostly zeros) because:\n",
    "- Each review contains only a small subset of all possible words\n",
    "- Most words don't appear in most reviews\n",
    "- This is normal and expected for text data\n",
    "\n",
    "Let's visualize what the feature matrix looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sparse matrix to dense for visualization (only for small samples!)\n",
    "# Note: For large datasets, keep it sparse to save memory\n",
    "X_sample = X[:5].toarray()\n",
    "\n",
    "# Get feature names (words)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "df_features = pd.DataFrame(\n",
    "    X_sample,\n",
    "    columns=feature_names,\n",
    "    index=[f\"Review {i+1}\" for i in range(5)]\n",
    ")\n",
    "\n",
    "# Show only columns (words) that appear in these 5 reviews\n",
    "non_zero_cols = df_features.columns[df_features.sum() > 0]\n",
    "print(f\"Showing {len(non_zero_cols)} words that appear in the first 5 reviews:\")\n",
    "display(df_features[non_zero_cols[:20]])  # Show first 20 words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Split Data into Training and Testing Sets\n",
    "\n",
    "**Why split the data?**\n",
    "\n",
    "We need to:\n",
    "1. **Train** the model on one portion of data\n",
    "2. **Test** the model on unseen data to evaluate its performance\n",
    "3. **Prevent overfitting** - ensure the model generalizes to new data\n",
    "\n",
    "**Important:** We split AFTER preprocessing to avoid data leakage (information from test set influencing training)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data: 80% training, 20% testing\n",
    "# stratify=y ensures same class distribution in both sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=SEED,\n",
    "    stratify=y  # Maintain class balance\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} reviews\")\n",
    "print(f\"Test set: {X_test.shape[0]} reviews\")\n",
    "print(\"\\nTraining label distribution:\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "print(\"\\nTest label distribution:\")\n",
    "print(pd.Series(y_test).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Train a Classifier\n",
    "\n",
    "We'll use a **Logistic Regression** classifier, which is:\n",
    "- **Fast** and efficient for text classification\n",
    "- **Well-suited** for count-based features (like our word counts)\n",
    "- **Simple** to understand and interpret\n",
    "- **Effective** for text classification tasks\n",
    "- **Provides probability estimates** for each class\n",
    "\n",
    "**How Logistic Regression works (simplified):**\n",
    "1. Learns weights for each feature (word) that indicate its importance for each class\n",
    "2. Uses a logistic function to convert weighted sums into probabilities\n",
    "3. Predicts the class with highest probability\n",
    "\n",
    "Logistic Regression is a linear classifier that works well with sparse, high-dimensional text features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Create and train the classifier\n",
    "# max_iter=1000 ensures convergence for large datasets\n",
    "classifier = LogisticRegression(max_iter=1000, random_state=SEED)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "print(\"Classifier trained successfully!\")\n",
    "print(f\"Number of features learned: {classifier.coef_.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Evaluate the Classifier\n",
    "\n",
    "Now let's evaluate how well our classifier performs on the test set. We'll use several metrics:\n",
    "\n",
    "- **Accuracy**: Overall percentage of correct predictions\n",
    "- **Precision**: Of all predictions for a class, how many were correct?\n",
    "- **Recall**: Of all actual instances of a class, how many did we find?\n",
    "- **F1-Score**: Harmonic mean of precision and recall (balances both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test set\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy:.2%}\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Detailed Classification Report:\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Understanding the Classification Report:**\n",
    "\n",
    "- **Precision**: When the model predicts a class, how often is it correct?\n",
    "  - High precision = few false positives\n",
    "  \n",
    "- **Recall**: How many of the actual instances of a class did we catch?\n",
    "  - High recall = few false negatives\n",
    "  \n",
    "- **F1-Score**: Balances precision and recall\n",
    "  - Useful when you need a single metric\n",
    "  \n",
    "- **Support**: Number of actual instances of each class in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create confusion matrix for visualization\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Display as DataFrame for better readability\n",
    "cm_df = pd.DataFrame(\n",
    "    cm,\n",
    "    index=[f\"Actual {label}\" for label in classifier.classes_],\n",
    "    columns=[f\"Predicted {label}\" for label in classifier.classes_]\n",
    ")\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(\"(Rows = Actual, Columns = Predicted)\")\n",
    "display(cm_df)\n",
    "\n",
    "# Visualize confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(classifier.classes_))\n",
    "plt.xticks(tick_marks, classifier.classes_, rotation=45)\n",
    "plt.yticks(tick_marks, classifier.classes_)\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "\n",
    "# Add text annotations\n",
    "thresh = cm.max() / 2.\n",
    "for i, j in np.ndindex(cm.shape):\n",
    "    plt.text(j, i, format(cm[i, j], 'd'),\n",
    "             horizontalalignment=\"center\",\n",
    "             color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading the Confusion Matrix:**\n",
    "\n",
    "- **Diagonal elements** (top-left to bottom-right): Correct predictions\n",
    "- **Off-diagonal elements**: Misclassifications\n",
    "  - Example: If \"Actual Negative\" row has a number in \"Predicted Positive\" column, those are negative reviews incorrectly classified as positive\n",
    "\n",
    "The confusion matrix helps us understand:\n",
    "- Which classes are confused with each other\n",
    "- Whether errors are balanced or biased toward certain classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Analyze Important Features\n",
    "\n",
    "Let's see which words are most important for each class. This helps us understand what the model learned and provides interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature names (words)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Get coefficients for each class\n",
    "# Higher values = more indicative of that class\n",
    "coefficients = classifier.coef_\n",
    "\n",
    "# Create DataFrame showing top words for each class\n",
    "top_words_per_class = {}\n",
    "for idx, class_label in enumerate(classifier.classes_):\n",
    "    # Get indices of top words for this class\n",
    "    top_indices = np.argsort(coefficients[idx])[-20:][::-1]  # Top 20 words\n",
    "    top_words = [(feature_names[i], coefficients[idx][i]) for i in top_indices]\n",
    "    top_words_per_class[class_label] = top_words\n",
    "\n",
    "# Display results\n",
    "for class_label, words in top_words_per_class.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Top 20 words for class: {class_label}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    df_top = pd.DataFrame(words, columns=['Word', 'Coefficient']).style.background_gradient(cmap='Greens')\n",
    "    display(df_top.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpreting Feature Importance:**\n",
    "\n",
    "The coefficients tell us how strongly each word is associated with each class:\n",
    "- **Higher coefficient** = word is more indicative of that class\n",
    "- **Lower (more negative) coefficient** = word is less indicative of that class\n",
    "- Words with high coefficients for \"Positive\" are likely positive sentiment words\n",
    "- Words with high coefficients for \"Negative\" are likely negative sentiment words\n",
    "\n",
    "**Compare with EDA results:** Do these top words match the words we found in our earlier EDA analysis? This validates that the model learned meaningful patterns!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Test on Sample Reviews\n",
    "\n",
    "Let's test our classifier on some example reviews to see it in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Get test indices in the original dataframe\n",
    "# train_test_split maintains order, so we need to track which rows went to test set\n",
    "_, test_indices_original = train_test_split(\n",
    "    df_normal.index,\n",
    "    test_size=0.2,\n",
    "    random_state=SEED,\n",
    "    stratify=df_normal['label']\n",
    ")\n",
    "\n",
    "# Select a few random test examples\n",
    "np.random.seed(SEED)\n",
    "# FIX: For sparse matrices, use shape[0] instead of len()\n",
    "sample_test_indices = np.random.choice(X_test.shape[0], size=5, replace=False)\n",
    "\n",
    "print(\"Sample Predictions:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# For a more visual display, let's build a table of predictions and use color to show confidence\n",
    "\n",
    "viz_rows = []\n",
    "for test_idx in sample_test_indices:\n",
    "    original_df_idx = test_indices_original[test_idx]\n",
    "    text_snippet = df_normal.loc[original_df_idx, 'text'][:80] + (\"...\" if len(df_normal.loc[original_df_idx, 'text']) > 80 else \"\")\n",
    "    actual = y_test[test_idx]\n",
    "    prediction = classifier.predict(X_test[test_idx:test_idx+1])[0]\n",
    "    probs = classifier.predict_proba(X_test[test_idx:test_idx+1])[0]\n",
    "    confidence = probs[classifier.classes_.tolist().index(prediction)]\n",
    "    viz_rows.append({\n",
    "        \"Review #\": test_idx,\n",
    "        \"Snippet\": text_snippet,\n",
    "        \"Actual Label\": actual,\n",
    "        \"Predicted Label\": prediction,\n",
    "        \"Confidence\": confidence,\n",
    "        **{f\"P({cls})\": p for cls, p in zip(classifier.classes_, probs)}\n",
    "    })\n",
    "\n",
    "viz_df = pd.DataFrame(viz_rows)\n",
    "# True-match in green, wrong in red\n",
    "def highlight_prediction(row):\n",
    "    color = \"\"\n",
    "    if row['Actual Label'] == row['Predicted Label']:\n",
    "        color = \"background-color: #d4f4dd\"  # light green\n",
    "    else:\n",
    "        color = \"background-color: #f4cccc\"  # light red\n",
    "    return [color]*len(row)\n",
    "# Display styled table, coloring accuracy and using a confidence gradient on \"Confidence\"\n",
    "viz_df_styled = (viz_df.style\n",
    "    .apply(highlight_prediction, axis=1)\n",
    "    .background_gradient(subset=['Confidence'], cmap='Blues')\n",
    "    .format({col: \"{:.2%}\" for col in ['Confidence'] + [f\"P({cls})\" for cls in classifier.classes_]})\n",
    ")\n",
    "display(viz_df_styled)\n",
    "\n",
    "# Also, show barplots of the predicted probability for each review\n",
    "for idx, row in viz_df.iterrows():\n",
    "    plt.figure(figsize=(4,2))\n",
    "    plt.bar(classifier.classes_, [row[f\"P({cls})\"] for cls in classifier.classes_], color=['#d1e0e0' if row['Predicted Label']==cls else '#ffe0b2' for cls in classifier.classes_])\n",
    "    plt.title(f\"Review #{row['Review #']} prediction\\nActual: {row['Actual Label']} | Predicted: {row['Predicted Label']} ({row['Confidence']:.0%})\")\n",
    "    plt.ylabel('Probability')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary: What We Learned\n",
    "\n",
    "**Key Takeaways:**\n",
    "\n",
    "- **Simple approaches work**: Word counts (Bag of Words) can be effective for text classification\n",
    "- **Preprocessing matters**: The cleaning, normalization, and stemming we did earlier improved our features\n",
    "- **Interpretability**: We can see which words drive predictions, making the model explainable\n",
    "- **Evaluation is crucial**: Always test on unseen data to measure real-world performance\n",
    "\n",
    "**Next Steps (for future exploration):**\n",
    "\n",
    "- Try **TF-IDF** instead of raw counts (weights words by importance)\n",
    "- Experiment with different classifiers (SVM, Random Forest, etc.)\n",
    "- Use **word embeddings** (like Word2Vec or pre-trained embeddings) for richer features\n",
    "- Fine-tune **transformer models** (like BERT) for state-of-the-art performance\n",
    "\n",
    "---\n",
    "\n",
    "**Remember**: This is a foundational approach. Modern NLP often uses more sophisticated methods, but understanding word counts and simple classifiers is essential for building intuition about how text classification works!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
